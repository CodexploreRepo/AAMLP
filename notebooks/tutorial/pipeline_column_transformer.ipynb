{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn Pipeline and ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "- Reference: [How to Improve Machine Learning Code Quality with Scikit-learn Pipeline and ColumnTransformer](https://www.freecodecamp.org/news/machine-learning-pipeline/)\n",
    "### Scikit-learn `Pipeline`\n",
    "- Before training a model, you should split your data into a training set and a test set. Each dataset will go through the data cleaning and preprocessing steps before you put it in a machine learning model.\n",
    "- The Scikit-learn `Pipeline` is a tool that links all steps of data manipulation together to create a pipeline.\n",
    "    - It is also easier to perform `GridSearchCV` without data leakage from the test set.\n",
    "<p align=\"center\"><img src=\"../../assets/img/sklearn-pipeline.png\" width=500></p>\n",
    "\n",
    "- The `Pipeline` constructor takes a list of (name,estimator) pairs (2-tuples) defining a sequence of steps.\n",
    "```Python\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    (\"impute\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"standardize\", StandardScaler()),\n",
    "])\n",
    "```\n",
    "- If you don’t want to name the transformers, you can use the `make_pipeline()` function instead\n",
    "```Python\n",
    "num_pipeline = make_pipeline(\n",
    "                OutlierRemover(), # custom transformer\n",
    "                SimpleImputer(strategy=\"median\"),  \n",
    "                MinMaxScaler()\n",
    ")\n",
    "```\n",
    "### Scikit-learn `ColumnTransformer`\n",
    "- `ColumnTransformer` will transform each group of dataframe columns separately and combine them later. This is useful in the data preprocessing process.\n",
    "\n",
    "<p align=\"center\"><img src=\"../../assets/img/sklearn-columntransformer.png\" width=500></p>\n",
    "\n",
    "- For example, the following `ColumnTransformer` will apply `num_pipeline` (the one which is defined above) to the numerical attributes and `cat_pipeline` to the categorical attribute:\n",
    "\n",
    "```Python\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_attribs = [\"longitude\", \"latitude\", \"housing_median_age\", \"total_rooms\",\n",
    "               \"total_bedrooms\", \"population\", \"households\", \"median_income\"]\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "cat_pipeline = make_pipeline(\n",
    "    SimpleImputer(strategy=\"most_frequent\"),\n",
    "    OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "\n",
    "preprocessing = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_attribs),\n",
    "    (\"cat\", cat_pipeline, cat_attribs),\n",
    "])\n",
    "```\n",
    "- If you don’t care about naming the transformers, you can use `make_column_transformer()`\n",
    "\n",
    "```Python\n",
    "from sklearn.compose import make_column_selector, make_column_transformer\n",
    "\n",
    "preprocessing = make_column_transformer(\n",
    "    (num_pipeline, make_column_selector(dtype_include=np.number)),\n",
    "    (cat_pipeline, make_column_selector(dtype_include=\"category\")),\n",
    ")\n",
    "```\n",
    "\n",
    "#### Column Selector\n",
    "- Since listing all the column names is not very convenient, Scikit-Learn provides a make_column_selector() function that returns a selector function you can use to automatically select all the features of a given type, such as numerical or categorical. \n",
    "```Python\n",
    "from sklearn.compose import make_column_selector\n",
    "selector = make_column_selector(dtype_include=np.number)\n",
    "selected_columns = selector(df)\n",
    "selected_columns #  ['city_development_index', 'training_hours']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, OrdinalEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enrollee_id</th>\n",
       "      <th>city</th>\n",
       "      <th>city_development_index</th>\n",
       "      <th>gender</th>\n",
       "      <th>relevent_experience</th>\n",
       "      <th>enrolled_university</th>\n",
       "      <th>education_level</th>\n",
       "      <th>major_discipline</th>\n",
       "      <th>experience</th>\n",
       "      <th>company_size</th>\n",
       "      <th>company_type</th>\n",
       "      <th>last_new_job</th>\n",
       "      <th>training_hours</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8949</td>\n",
       "      <td>city_103</td>\n",
       "      <td>0.920</td>\n",
       "      <td>Male</td>\n",
       "      <td>Has relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>STEM</td>\n",
       "      <td>&gt;20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29725</td>\n",
       "      <td>city_40</td>\n",
       "      <td>0.776</td>\n",
       "      <td>Male</td>\n",
       "      <td>No relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>STEM</td>\n",
       "      <td>15</td>\n",
       "      <td>50-99</td>\n",
       "      <td>Pvt Ltd</td>\n",
       "      <td>&gt;4</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11561</td>\n",
       "      <td>city_21</td>\n",
       "      <td>0.624</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No relevent experience</td>\n",
       "      <td>Full time course</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>STEM</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never</td>\n",
       "      <td>83</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33241</td>\n",
       "      <td>city_115</td>\n",
       "      <td>0.789</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No relevent experience</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Business Degree</td>\n",
       "      <td>&lt;1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pvt Ltd</td>\n",
       "      <td>never</td>\n",
       "      <td>52</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>666</td>\n",
       "      <td>city_162</td>\n",
       "      <td>0.767</td>\n",
       "      <td>Male</td>\n",
       "      <td>Has relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Masters</td>\n",
       "      <td>STEM</td>\n",
       "      <td>&gt;20</td>\n",
       "      <td>50-99</td>\n",
       "      <td>Funded Startup</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   enrollee_id      city  city_development_index gender  \\\n",
       "0         8949  city_103                   0.920   Male   \n",
       "1        29725   city_40                   0.776   Male   \n",
       "2        11561   city_21                   0.624    NaN   \n",
       "3        33241  city_115                   0.789    NaN   \n",
       "4          666  city_162                   0.767   Male   \n",
       "\n",
       "       relevent_experience enrolled_university education_level  \\\n",
       "0  Has relevent experience       no_enrollment        Graduate   \n",
       "1   No relevent experience       no_enrollment        Graduate   \n",
       "2   No relevent experience    Full time course        Graduate   \n",
       "3   No relevent experience                 NaN        Graduate   \n",
       "4  Has relevent experience       no_enrollment         Masters   \n",
       "\n",
       "  major_discipline experience company_size    company_type last_new_job  \\\n",
       "0             STEM        >20          NaN             NaN            1   \n",
       "1             STEM         15        50-99         Pvt Ltd           >4   \n",
       "2             STEM          5          NaN             NaN        never   \n",
       "3  Business Degree         <1          NaN         Pvt Ltd        never   \n",
       "4             STEM        >20        50-99  Funded Startup            4   \n",
       "\n",
       "   training_hours  target  \n",
       "0              36     1.0  \n",
       "1              47     0.0  \n",
       "2              83     0.0  \n",
       "3              52     1.0  \n",
       "4               8     0.0  "
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../.././data/common_datasets/aug_train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19158 entries, 0 to 19157\n",
      "Data columns (total 14 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   enrollee_id             19158 non-null  int64  \n",
      " 1   city                    19158 non-null  object \n",
      " 2   city_development_index  19158 non-null  float64\n",
      " 3   gender                  14650 non-null  object \n",
      " 4   relevent_experience     19158 non-null  object \n",
      " 5   enrolled_university     18772 non-null  object \n",
      " 6   education_level         18698 non-null  object \n",
      " 7   major_discipline        16345 non-null  object \n",
      " 8   experience              19093 non-null  object \n",
      " 9   company_size            13220 non-null  object \n",
      " 10  company_type            13018 non-null  object \n",
      " 11  last_new_job            18735 non-null  object \n",
      " 12  training_hours          19158 non-null  int64  \n",
      " 13  target                  19158 non-null  float64\n",
      "dtypes: float64(2), int64(2), object(10)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Sets of Columns to be Transformed in Different Ways\n",
    "num_cols = ['city_development_index', 'training_hours']\n",
    "\n",
    "oh_cat_cols = ['gender', 'enrolled_university', 'education_level', 'major_discipline', 'company_size', 'company_type']\n",
    "ord_cat_cols = ['relevent_experience', 'experience', 'last_new_job']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create Pipelines for Numerical and Categorical Features\n",
    "num_pipeline = Pipeline(steps=[\n",
    "    ('impute', SimpleImputer(strategy='mean')),\n",
    "    ('scale', StandardScaler())\n",
    "])\n",
    "oh_cat_pipeline = Pipeline(steps=[\n",
    "    ('impute', SimpleImputer(strategy='most_frequent')),\n",
    "    ('one-hot',OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "ord_cat_pipeline = Pipeline(steps=[\n",
    "    ('impute',  SimpleImputer(strategy='most_frequent')),\n",
    "    ('one-hot', OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "col_trans = ColumnTransformer(transformers=[\n",
    "        ('num_pipeline', num_pipeline, num_cols),\n",
    "        ('oh_cat_pipeline', oh_cat_pipeline, oh_cat_cols),\n",
    "        ('ord_cat_pipeline', ord_cat_pipeline, ord_cat_cols),\n",
    "\n",
    "    ],\n",
    "    remainder='drop',   # 'drop' and 'passthrough'\n",
    "    n_jobs=-1)          # n_job = -1 means that we'll be using all processors to run in parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- you can get the column names using `col_trans.get_feature_names_out()` and wrap the data in a nice DataFrame as we did before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_pipeline__city_development_index</th>\n",
       "      <th>num_pipeline__training_hours</th>\n",
       "      <th>oh_cat_pipeline__gender_Female</th>\n",
       "      <th>oh_cat_pipeline__gender_Male</th>\n",
       "      <th>oh_cat_pipeline__gender_Other</th>\n",
       "      <th>oh_cat_pipeline__enrolled_university_Full time course</th>\n",
       "      <th>oh_cat_pipeline__enrolled_university_Part time course</th>\n",
       "      <th>oh_cat_pipeline__enrolled_university_no_enrollment</th>\n",
       "      <th>oh_cat_pipeline__education_level_Graduate</th>\n",
       "      <th>oh_cat_pipeline__education_level_High School</th>\n",
       "      <th>...</th>\n",
       "      <th>oh_cat_pipeline__company_size_&lt;10</th>\n",
       "      <th>oh_cat_pipeline__company_type_Early Stage Startup</th>\n",
       "      <th>oh_cat_pipeline__company_type_Funded Startup</th>\n",
       "      <th>oh_cat_pipeline__company_type_NGO</th>\n",
       "      <th>oh_cat_pipeline__company_type_Other</th>\n",
       "      <th>oh_cat_pipeline__company_type_Public Sector</th>\n",
       "      <th>oh_cat_pipeline__company_type_Pvt Ltd</th>\n",
       "      <th>ord_cat_pipeline__relevent_experience</th>\n",
       "      <th>ord_cat_pipeline__experience</th>\n",
       "      <th>ord_cat_pipeline__last_new_job</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.738919</td>\n",
       "      <td>-0.488985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.428410</td>\n",
       "      <td>-0.305825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.660590</td>\n",
       "      <td>0.293607</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.323026</td>\n",
       "      <td>-0.222571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.501368</td>\n",
       "      <td>-0.955209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_pipeline__city_development_index  num_pipeline__training_hours  \\\n",
       "0                              0.738919                     -0.488985   \n",
       "1                             -0.428410                     -0.305825   \n",
       "2                             -1.660590                      0.293607   \n",
       "3                             -0.323026                     -0.222571   \n",
       "4                             -0.501368                     -0.955209   \n",
       "\n",
       "   oh_cat_pipeline__gender_Female  oh_cat_pipeline__gender_Male  \\\n",
       "0                             0.0                           1.0   \n",
       "1                             0.0                           1.0   \n",
       "2                             0.0                           1.0   \n",
       "3                             0.0                           1.0   \n",
       "4                             0.0                           1.0   \n",
       "\n",
       "   oh_cat_pipeline__gender_Other  \\\n",
       "0                            0.0   \n",
       "1                            0.0   \n",
       "2                            0.0   \n",
       "3                            0.0   \n",
       "4                            0.0   \n",
       "\n",
       "   oh_cat_pipeline__enrolled_university_Full time course  \\\n",
       "0                                                0.0       \n",
       "1                                                0.0       \n",
       "2                                                1.0       \n",
       "3                                                0.0       \n",
       "4                                                0.0       \n",
       "\n",
       "   oh_cat_pipeline__enrolled_university_Part time course  \\\n",
       "0                                                0.0       \n",
       "1                                                0.0       \n",
       "2                                                0.0       \n",
       "3                                                0.0       \n",
       "4                                                0.0       \n",
       "\n",
       "   oh_cat_pipeline__enrolled_university_no_enrollment  \\\n",
       "0                                                1.0    \n",
       "1                                                1.0    \n",
       "2                                                0.0    \n",
       "3                                                1.0    \n",
       "4                                                1.0    \n",
       "\n",
       "   oh_cat_pipeline__education_level_Graduate  \\\n",
       "0                                        1.0   \n",
       "1                                        1.0   \n",
       "2                                        1.0   \n",
       "3                                        1.0   \n",
       "4                                        0.0   \n",
       "\n",
       "   oh_cat_pipeline__education_level_High School  ...  \\\n",
       "0                                           0.0  ...   \n",
       "1                                           0.0  ...   \n",
       "2                                           0.0  ...   \n",
       "3                                           0.0  ...   \n",
       "4                                           0.0  ...   \n",
       "\n",
       "   oh_cat_pipeline__company_size_<10  \\\n",
       "0                                0.0   \n",
       "1                                0.0   \n",
       "2                                0.0   \n",
       "3                                0.0   \n",
       "4                                0.0   \n",
       "\n",
       "   oh_cat_pipeline__company_type_Early Stage Startup  \\\n",
       "0                                                0.0   \n",
       "1                                                0.0   \n",
       "2                                                0.0   \n",
       "3                                                0.0   \n",
       "4                                                0.0   \n",
       "\n",
       "   oh_cat_pipeline__company_type_Funded Startup  \\\n",
       "0                                           0.0   \n",
       "1                                           0.0   \n",
       "2                                           0.0   \n",
       "3                                           0.0   \n",
       "4                                           1.0   \n",
       "\n",
       "   oh_cat_pipeline__company_type_NGO  oh_cat_pipeline__company_type_Other  \\\n",
       "0                                0.0                                  0.0   \n",
       "1                                0.0                                  0.0   \n",
       "2                                0.0                                  0.0   \n",
       "3                                0.0                                  0.0   \n",
       "4                                0.0                                  0.0   \n",
       "\n",
       "   oh_cat_pipeline__company_type_Public Sector  \\\n",
       "0                                          0.0   \n",
       "1                                          0.0   \n",
       "2                                          0.0   \n",
       "3                                          0.0   \n",
       "4                                          0.0   \n",
       "\n",
       "   oh_cat_pipeline__company_type_Pvt Ltd  \\\n",
       "0                                    1.0   \n",
       "1                                    1.0   \n",
       "2                                    1.0   \n",
       "3                                    1.0   \n",
       "4                                    0.0   \n",
       "\n",
       "   ord_cat_pipeline__relevent_experience  ord_cat_pipeline__experience  \\\n",
       "0                                    0.0                          21.0   \n",
       "1                                    1.0                           6.0   \n",
       "2                                    1.0                          15.0   \n",
       "3                                    1.0                          20.0   \n",
       "4                                    0.0                          21.0   \n",
       "\n",
       "   ord_cat_pipeline__last_new_job  \n",
       "0                             0.0  \n",
       "1                             4.0  \n",
       "2                             5.0  \n",
       "3                             5.0  \n",
       "4                             3.0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transfomred_df = pd.DataFrame(col_trans.fit_transform(df), columns=col_trans.get_feature_names_out())\n",
    "transfomred_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You also can add the model to complete the full pipline from data processing + model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-42 {color: black;}#sk-container-id-42 pre{padding: 0;}#sk-container-id-42 div.sk-toggleable {background-color: white;}#sk-container-id-42 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-42 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-42 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-42 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-42 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-42 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-42 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-42 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-42 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-42 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-42 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-42 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-42 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-42 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-42 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-42 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-42 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-42 div.sk-item {position: relative;z-index: 1;}#sk-container-id-42 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-42 div.sk-item::before, #sk-container-id-42 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-42 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-42 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-42 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-42 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-42 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-42 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-42 div.sk-label-container {text-align: center;}#sk-container-id-42 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-42 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-42\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;col_trans&#x27;,\n",
       "                 ColumnTransformer(n_jobs=-1,\n",
       "                                   transformers=[(&#x27;num_pipeline&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;impute&#x27;,\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  (&#x27;scale&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [&#x27;city_development_index&#x27;,\n",
       "                                                   &#x27;training_hours&#x27;]),\n",
       "                                                 (&#x27;oh_cat_pipeline&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;impute&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;one-hot&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                  [&#x27;gende...\n",
       "                                                   &#x27;education_level&#x27;,\n",
       "                                                   &#x27;major_discipline&#x27;,\n",
       "                                                   &#x27;company_size&#x27;,\n",
       "                                                   &#x27;company_type&#x27;]),\n",
       "                                                 (&#x27;ord_cat_pipeline&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;impute&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;one-hot&#x27;,\n",
       "                                                                   OrdinalEncoder(handle_unknown=&#x27;use_encoded_value&#x27;,\n",
       "                                                                                  unknown_value=-1))]),\n",
       "                                                  [&#x27;relevent_experience&#x27;,\n",
       "                                                   &#x27;experience&#x27;,\n",
       "                                                   &#x27;last_new_job&#x27;])])),\n",
       "                (&#x27;model&#x27;, LogisticRegression(max_iter=1000, random_state=0))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-427\" type=\"checkbox\" ><label for=\"sk-estimator-id-427\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;col_trans&#x27;,\n",
       "                 ColumnTransformer(n_jobs=-1,\n",
       "                                   transformers=[(&#x27;num_pipeline&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;impute&#x27;,\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  (&#x27;scale&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [&#x27;city_development_index&#x27;,\n",
       "                                                   &#x27;training_hours&#x27;]),\n",
       "                                                 (&#x27;oh_cat_pipeline&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;impute&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;one-hot&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                  [&#x27;gende...\n",
       "                                                   &#x27;education_level&#x27;,\n",
       "                                                   &#x27;major_discipline&#x27;,\n",
       "                                                   &#x27;company_size&#x27;,\n",
       "                                                   &#x27;company_type&#x27;]),\n",
       "                                                 (&#x27;ord_cat_pipeline&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;impute&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;one-hot&#x27;,\n",
       "                                                                   OrdinalEncoder(handle_unknown=&#x27;use_encoded_value&#x27;,\n",
       "                                                                                  unknown_value=-1))]),\n",
       "                                                  [&#x27;relevent_experience&#x27;,\n",
       "                                                   &#x27;experience&#x27;,\n",
       "                                                   &#x27;last_new_job&#x27;])])),\n",
       "                (&#x27;model&#x27;, LogisticRegression(max_iter=1000, random_state=0))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-428\" type=\"checkbox\" ><label for=\"sk-estimator-id-428\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">col_trans: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(n_jobs=-1,\n",
       "                  transformers=[(&#x27;num_pipeline&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;impute&#x27;, SimpleImputer()),\n",
       "                                                 (&#x27;scale&#x27;, StandardScaler())]),\n",
       "                                 [&#x27;city_development_index&#x27;, &#x27;training_hours&#x27;]),\n",
       "                                (&#x27;oh_cat_pipeline&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;impute&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;one-hot&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                 [&#x27;gender&#x27;, &#x27;enrolled_university&#x27;,\n",
       "                                  &#x27;education_level&#x27;, &#x27;major_discipline&#x27;,\n",
       "                                  &#x27;company_size&#x27;, &#x27;company_type&#x27;]),\n",
       "                                (&#x27;ord_cat_pipeline&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;impute&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;one-hot&#x27;,\n",
       "                                                  OrdinalEncoder(handle_unknown=&#x27;use_encoded_value&#x27;,\n",
       "                                                                 unknown_value=-1))]),\n",
       "                                 [&#x27;relevent_experience&#x27;, &#x27;experience&#x27;,\n",
       "                                  &#x27;last_new_job&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-429\" type=\"checkbox\" ><label for=\"sk-estimator-id-429\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num_pipeline</label><div class=\"sk-toggleable__content\"><pre>[&#x27;city_development_index&#x27;, &#x27;training_hours&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-430\" type=\"checkbox\" ><label for=\"sk-estimator-id-430\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-431\" type=\"checkbox\" ><label for=\"sk-estimator-id-431\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-432\" type=\"checkbox\" ><label for=\"sk-estimator-id-432\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">oh_cat_pipeline</label><div class=\"sk-toggleable__content\"><pre>[&#x27;gender&#x27;, &#x27;enrolled_university&#x27;, &#x27;education_level&#x27;, &#x27;major_discipline&#x27;, &#x27;company_size&#x27;, &#x27;company_type&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-433\" type=\"checkbox\" ><label for=\"sk-estimator-id-433\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-434\" type=\"checkbox\" ><label for=\"sk-estimator-id-434\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-435\" type=\"checkbox\" ><label for=\"sk-estimator-id-435\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ord_cat_pipeline</label><div class=\"sk-toggleable__content\"><pre>[&#x27;relevent_experience&#x27;, &#x27;experience&#x27;, &#x27;last_new_job&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-436\" type=\"checkbox\" ><label for=\"sk-estimator-id-436\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-437\" type=\"checkbox\" ><label for=\"sk-estimator-id-437\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OrdinalEncoder</label><div class=\"sk-toggleable__content\"><pre>OrdinalEncoder(handle_unknown=&#x27;use_encoded_value&#x27;, unknown_value=-1)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-438\" type=\"checkbox\" ><label for=\"sk-estimator-id-438\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, random_state=0)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('col_trans',\n",
       "                 ColumnTransformer(n_jobs=-1,\n",
       "                                   transformers=[('num_pipeline',\n",
       "                                                  Pipeline(steps=[('impute',\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  ('scale',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['city_development_index',\n",
       "                                                   'training_hours']),\n",
       "                                                 ('oh_cat_pipeline',\n",
       "                                                  Pipeline(steps=[('impute',\n",
       "                                                                   SimpleImputer(strategy='most_frequent')),\n",
       "                                                                  ('one-hot',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  ['gende...\n",
       "                                                   'education_level',\n",
       "                                                   'major_discipline',\n",
       "                                                   'company_size',\n",
       "                                                   'company_type']),\n",
       "                                                 ('ord_cat_pipeline',\n",
       "                                                  Pipeline(steps=[('impute',\n",
       "                                                                   SimpleImputer(strategy='most_frequent')),\n",
       "                                                                  ('one-hot',\n",
       "                                                                   OrdinalEncoder(handle_unknown='use_encoded_value',\n",
       "                                                                                  unknown_value=-1))]),\n",
       "                                                  ['relevent_experience',\n",
       "                                                   'experience',\n",
       "                                                   'last_new_job'])])),\n",
       "                ('model', LogisticRegression(max_iter=1000, random_state=0))])"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add a Model to the final pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000, random_state=0)\n",
    "clf_pipeline = Pipeline(steps=[\n",
    "    ('col_trans', col_trans),\n",
    "    ('model', clf)\n",
    "])\n",
    "clf_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score: 0.7656576200417536\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(columns='target')\n",
    "y = df['target']\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "\n",
    "clf_pipeline.fit(X_train, y_train)\n",
    "# preds = clf_pipeline.predict(X_test)\n",
    "score = clf_pipeline.score(X_test, y_test)\n",
    "\n",
    "print(f\"Model score: {score}\") # model accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Transformers\n",
    "- Although Scikit-Learn provides many useful transformers, you will need to write your own for tasks such as custom transformations, cleanup operations, or combining specific attributes.Although Scikit-Learn provides many useful transformers, you will need to write your own for tasks such as custom transformations, cleanup operations, or combining specific attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Custom Function Transformer\n",
    "- For transformations that don’t require any training (i.e. not require `.fit()`), you can just write a **function** that takes a NumPy array as input and outputs the transformed array.\n",
    "- The `inverse_func` argument is optional. It lets you specify an inverse transform function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3.583519\n",
       "1    3.850148\n",
       "2    4.418841\n",
       "3    3.951244\n",
       "4    2.079442\n",
       "Name: training_hours, dtype: float64"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "log_transformer = FunctionTransformer(np.log, inverse_func=np.exp)\n",
    "log_training_hours = log_transformer.transform(df['training_hours'])\n",
    "log_training_hours[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `FunctionTransformer` is also useful to combine features. \n",
    "    - For example, here’s a `FunctionTransformer` that computes the ratio between the input features 0 and 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_transformer = FunctionTransformer(lambda X: X[:, [0]] / X[:, [1]])\n",
    "ratio_transformer.transform(df[[\"people\", \"room\"]].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The transformation function can take hyperparameters as additional arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_mul(X: np.array, multipler: int) -> np.array:\n",
    "    return (X[:, 0] - X[:, 1]) * multipler\n",
    "\n",
    "diff_mul_transformer = FunctionTransformer(diff_mul) \n",
    "diff_mul_transformer.transform(df[['ndp', 'discount']].value,\n",
    "                               kw_args={\"mutliplier\": 2}  # provide the \"multipler\" input to function diff_mul as 2\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Custom Class Transformer\n",
    "- Custom Class Transformer is to have the transformer with trainable parameters using `fit()` method and using them later in the `transform()` method\n",
    "- Custom Class Transformer requires:\n",
    "    - `BaseEstimator` as a base class (and avoid using `*args` and `**kwargs` in your constructor), you will also get two extra methods: `get_params()` and `set_params()`, which will be useful for automatic hyperparameter tuning.\n",
    "    - `TransformerMixin` as a base class to auto-have `.fit_transform()` \n",
    "    - Define `fit(X, y)` method with `y=None` as required and it must return `self`\n",
    "        - Note: `X` should be `np.ndarray` type as if it is in the a step in the Pipeline, the data is passed only with the Numpy array, not Pandas dataframe \n",
    "    - Define `transformer()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils.validation import check_array, check_is_fitted\n",
    "from typing import Union\n",
    "\n",
    "class StandardScalerClone(BaseEstimator, TransformerMixin): \n",
    "    def __init__(self, with_mean=True):                 # [REQUIRED] no *args or **kwargs as using BaseEstimator as a base class\n",
    "        self.with_mean = with_mean\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray=None):   # [REQUIRED] y is required even though we don't use it\n",
    "        X = check_array(X)                              # checks that X is an array with finite float values\n",
    "\n",
    "        self.mean_ = X.mean(axis=0)                     # [REQUIRED] learned attributes have end with \"_\"\n",
    "        self.scale_ = X.std(axis=0)\n",
    "        self.n_features_in_ = X.shape[1]                # [REQUIRED] every estimator stores this in fit()\n",
    "        \n",
    "        return self                                     # [REQUIRED] always return self!\n",
    "\n",
    "    def transform(self, X: Union[pd.DataFrame, np.ndarray]) -> Union[pd.DataFrame, np.ndarray]:\n",
    "        check_is_fitted(self)                           # [REQUIRED] looks for learned attributes (with trailing _)\n",
    "        #self.columns = X.columns\n",
    "        \n",
    "        X = check_array(X)\n",
    "        \n",
    "        assert self.n_features_in_ == X.shape[1]\n",
    "        if self.with_mean:\n",
    "            X = X - self.mean_\n",
    "\n",
    "        return X / self.scale_\n",
    "    \n",
    "    # def get_feature_names_out(self, input_features):\n",
    "    #     return [col for col in self.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pipelines for Numerical and Categorical Features\n",
    "num_pipeline_cloned = Pipeline(steps=[\n",
    "    ('impute', SimpleImputer(strategy='mean')),\n",
    "    ('scale', StandardScalerClone())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.4889846 ],\n",
       "       [-0.30582494],\n",
       "       [ 0.29360665],\n",
       "       [-0.22257056],\n",
       "       [-0.95520917]])"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_pipeline_cloned.fit_transform(df[[\"training_hours\"]])[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.4889846 ],\n",
       "       [-0.30582494],\n",
       "       [ 0.29360665],\n",
       "       [-0.22257056],\n",
       "       [-0.95520917]])"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare the result with the default standard scaler\n",
    "num_pipeline.fit_transform(df[[\"training_hours\"]])[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the pipeline\n",
    "# import joblib\n",
    "\n",
    "# # Save pipeline to file \"pipe.joblib\"\n",
    "# joblib.dump(clf_pipeline,\"pipe.joblib\")\n",
    "\n",
    "# # Load pipeline when you want to use\n",
    "# same_pipe = joblib.load(\"pipe.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Find the Best Hyperparameter and Data Preparation Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to find the best hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check the list of adjustable parameters \n",
    "# clf_pipeline.get_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set param: step_name + '_' + parameter\n",
    "clf_pipeline.set_params(model_C = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score of train set: 0.7671934994024873\n",
      "Best parameter set: {'model__C': 0.03359818286283781, 'model__penalty': 'l2'}\n",
      "Test Score: 0.7643528183716075\n"
     ]
    }
   ],
   "source": [
    "grid_params = {'model__penalty' : ['l2'],\n",
    "               'model__C' : np.logspace(-4, 4, 20)}\n",
    "\n",
    "gs = GridSearchCV(clf_pipeline, grid_params, cv=5, scoring='accuracy')\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best Score of train set: {gs.best_score_}\")\n",
    "print(f\"Best parameter set: {gs.best_params_}\")\n",
    "print(f\"Test Score: {gs.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to find the Best Data Preparation Method: Skip a Step in a Pipeline\n",
    "- With the pipeline, we can create data transformation steps in the pipeline and perform a grid search to find the best step. A grid search will select which step to skip and compare the result of each case.\n",
    "- In grid search parameters, specify the steps you want to skip and set their value to `passthrough`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline2 = Pipeline(steps=[\n",
    "    ('impute', SimpleImputer(strategy='mean')),\n",
    "    ('minmax_scale', MinMaxScaler()), \n",
    "    ('std_scale', StandardScaler()), # add also 'std_scale'\n",
    "])\n",
    "\n",
    "col_trans2 = ColumnTransformer(transformers=[\n",
    "        ('num_pipeline', num_pipeline2, num_cols), # update with num_pipeline2\n",
    "        ('oh_cat_pipeline', oh_cat_pipeline, oh_cat_cols),\n",
    "        ('ord_cat_pipeline', ord_cat_pipeline, ord_cat_cols),\n",
    "\n",
    "    ],\n",
    "    remainder='drop',   # 'drop' and 'passthrough'\n",
    "    n_jobs=-1)          # n_job = -1 means that we'll be using all processors to run in parallel.\n",
    "\n",
    "clf_pipeline2 = Pipeline(steps=[\n",
    "    ('col_trans', col_trans2),\n",
    "    ('model', clf)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_step_params = [{'col_trans__num_pipeline__minmax_scale': ['passthrough']},\n",
    "                    {'col_trans__num_pipeline__std_scale': ['passthrough']}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score of train set: 0.7660189054504011\n",
      "Best parameter set: {'col_trans__num_pipeline__minmax_scale': 'passthrough'}\n",
      "Test Score: 0.7659185803757829\n"
     ]
    }
   ],
   "source": [
    "gs2 = GridSearchCV(clf_pipeline2, grid_step_params, scoring='accuracy')\n",
    "gs2.fit(X_train, y_train)\n",
    "print(f\"Best Score of train set: {gs2.best_score_}\")\n",
    "print(f\"Best parameter set: {gs2.best_params_}\")\n",
    "print(f\"Test Score: {gs2.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The best case is `minmax_scale : ‘passthrough’`, so `StandardScaler` is the best scaling method for this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Find the Best Hyperparameter Sets and the Best Data Preparation Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params = {'model__penalty' : ['l2'],\n",
    "               'model__C' : np.logspace(-4, 4, 20)}\n",
    "               \n",
    "grid_step_params = [{'col_trans__num_pipeline__minmax_scale': ['passthrough'], **grid_params},\n",
    "                    {'col_trans__num_pipeline__std_scale': ['passthrough'], **grid_params}\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score of train set: 0.7671934994024873\n",
      "Best parameter set: {'col_trans__num_pipeline__std_scale': 'passthrough', 'model__C': 0.03359818286283781, 'model__penalty': 'l2'}\n",
      "Test Score: 0.7643528183716075\n"
     ]
    }
   ],
   "source": [
    "gs3 = GridSearchCV(clf_pipeline2, grid_step_params, scoring='accuracy')\n",
    "gs3.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best Score of train set: {gs3.best_score_}\")\n",
    "print(f\"Best parameter set: {gs3.best_params_}\")\n",
    "print(f\"Test Score: {gs3.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to find the best models\n",
    "- The solution to this problem is to create a custom transformation that receives a model as an input and performs grid search to find the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "class ClfSwitcher(BaseEstimator):\n",
    "    def __init__(self, estimator = LogisticRegression()):\n",
    "            self.estimator = estimator\n",
    "            \n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "            self.estimator.fit(X, y)\n",
    "            return self\n",
    "            \n",
    "    def predict(self, X, y=None):\n",
    "            return self.estimator.predict(X)\n",
    "            \n",
    "    def predict_proba(self, X):\n",
    "            return self.estimator.predict_proba(X)\n",
    "            \n",
    "    def score(self, X, y):\n",
    "            return self.estimator.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_pipeline4 = Pipeline(steps=[\n",
    "    ('col_trans', col_trans2),\n",
    "    ('model', ClfSwitcher())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score of train set: 0.7661492408981738\n",
      "Best parameter set: {'col_trans__num_pipeline__minmax_scale': 'passthrough', 'model__estimator': LogisticRegression(max_iter=1000)}\n",
      "Test Score: 0.7659185803757829\n"
     ]
    }
   ],
   "source": [
    "grid_params = {'model__estimator' : [LogisticRegression(max_iter=1000), SVC(gamma='auto')]}\n",
    "               \n",
    "grid_step_params = [{'col_trans__num_pipeline__minmax_scale': ['passthrough'], **grid_params},\n",
    "                    {'col_trans__num_pipeline__std_scale': ['passthrough'], **grid_params}\n",
    "                    ]\n",
    "\n",
    "\n",
    "gs4 = GridSearchCV(clf_pipeline4, grid_step_params, scoring='accuracy')\n",
    "gs4.fit(X_train, y_train)\n",
    "print(f\"Best Score of train set: {gs4.best_score_}\")\n",
    "print(f\"Best parameter set: {gs4.best_params_}\")\n",
    "print(f\"Test Score: {gs4.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_col_trans__num_pipeline__minmax_scale</th>\n",
       "      <th>param_model__estimator</th>\n",
       "      <th>param_col_trans__num_pipeline__std_scale</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.168548</td>\n",
       "      <td>0.017555</td>\n",
       "      <td>0.013922</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>LogisticRegression(max_iter=1000)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'col_trans__num_pipeline__minmax_scale': 'pas...</td>\n",
       "      <td>0.762883</td>\n",
       "      <td>0.765416</td>\n",
       "      <td>0.765742</td>\n",
       "      <td>0.782708</td>\n",
       "      <td>0.753997</td>\n",
       "      <td>0.766149</td>\n",
       "      <td>0.009309</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.217746</td>\n",
       "      <td>0.040602</td>\n",
       "      <td>1.275425</td>\n",
       "      <td>0.029387</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>SVC(gamma='auto')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'col_trans__num_pipeline__minmax_scale': 'pas...</td>\n",
       "      <td>0.767776</td>\n",
       "      <td>0.765090</td>\n",
       "      <td>0.763132</td>\n",
       "      <td>0.775530</td>\n",
       "      <td>0.758238</td>\n",
       "      <td>0.765953</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.110988</td>\n",
       "      <td>0.026882</td>\n",
       "      <td>0.013632</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(max_iter=1000)</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>{'col_trans__num_pipeline__std_scale': 'passth...</td>\n",
       "      <td>0.762557</td>\n",
       "      <td>0.765090</td>\n",
       "      <td>0.766069</td>\n",
       "      <td>0.781403</td>\n",
       "      <td>0.754323</td>\n",
       "      <td>0.765888</td>\n",
       "      <td>0.008789</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.242711</td>\n",
       "      <td>0.028602</td>\n",
       "      <td>1.316997</td>\n",
       "      <td>0.025985</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SVC(gamma='auto')</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>{'col_trans__num_pipeline__std_scale': 'passth...</td>\n",
       "      <td>0.757665</td>\n",
       "      <td>0.751060</td>\n",
       "      <td>0.752692</td>\n",
       "      <td>0.757259</td>\n",
       "      <td>0.744209</td>\n",
       "      <td>0.752577</td>\n",
       "      <td>0.004902</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.168548      0.017555         0.013922        0.000678   \n",
       "1       2.217746      0.040602         1.275425        0.029387   \n",
       "2       0.110988      0.026882         0.013632        0.000757   \n",
       "3       2.242711      0.028602         1.316997        0.025985   \n",
       "\n",
       "  param_col_trans__num_pipeline__minmax_scale  \\\n",
       "0                                 passthrough   \n",
       "1                                 passthrough   \n",
       "2                                         NaN   \n",
       "3                                         NaN   \n",
       "\n",
       "              param_model__estimator param_col_trans__num_pipeline__std_scale  \\\n",
       "0  LogisticRegression(max_iter=1000)                                      NaN   \n",
       "1                  SVC(gamma='auto')                                      NaN   \n",
       "2  LogisticRegression(max_iter=1000)                              passthrough   \n",
       "3                  SVC(gamma='auto')                              passthrough   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'col_trans__num_pipeline__minmax_scale': 'pas...           0.762883   \n",
       "1  {'col_trans__num_pipeline__minmax_scale': 'pas...           0.767776   \n",
       "2  {'col_trans__num_pipeline__std_scale': 'passth...           0.762557   \n",
       "3  {'col_trans__num_pipeline__std_scale': 'passth...           0.757665   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.765416           0.765742           0.782708           0.753997   \n",
       "1           0.765090           0.763132           0.775530           0.758238   \n",
       "2           0.765090           0.766069           0.781403           0.754323   \n",
       "3           0.751060           0.752692           0.757259           0.744209   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.766149        0.009309                1  \n",
       "1         0.765953        0.005714                2  \n",
       "2         0.765888        0.008789                3  \n",
       "3         0.752577        0.004902                4  "
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gs4.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
